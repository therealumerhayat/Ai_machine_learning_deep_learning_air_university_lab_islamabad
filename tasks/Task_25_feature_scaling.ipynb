{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Muhammad Umer\n",
    "\n",
    "**Email** umerhayat282@gmail.com\n",
    "\n",
    "**Date** October 24, 2025\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **About this Notebook**\n",
    "\n",
    "This notebook demonstrates and explains seven key feature scaling techniques used in machine learning to normalize or standardize data before model training. Each method is applied practically with clear examples to show how the values change before and after scaling, along with a detailed explanation of when and why each technique should be used. The goal of this notebook is to help understand the impact of different scalers on data distribution and model performance, providing a strong foundation for preprocessing in ML workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Table of Contents**\n",
    "\n",
    "Click any link to jump to that section:\n",
    "\n",
    "1. [Explore data](#explore-data)\n",
    "2. [StandardScaler](#1-StandardScaler)\n",
    "3. [MinMaxScaler](#2-minmaxscaler)\n",
    "4. [MaxAbsScaler](#3-maxabsscaler)\n",
    "5. [RobustScaler](#4-robustscaler)\n",
    "6. [Normalizer](#5-normalizer)\n",
    "7. [QuantileTransformer](#6-quantiletransformer)\n",
    "8. [PowerTransformer](#7-powertransformer)\n",
    "9. [Overall Observations](#overall-observations-on-data-scaling)\n",
    "10. [Summary](#Summary:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "2d320acb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_data = pd.read_csv(r'D:\\Ai_machine_learning_deep_learning_air_university_lab_islamabad\\data\\Data.csv')\n",
    "df_employee = pd.read_csv(r'D:\\Ai_machine_learning_deep_learning_air_university_lab_islamabad\\data\\Employee.csv')\n",
    "df_heart_disease = pd.read_csv(r'D:\\Ai_machine_learning_deep_learning_air_university_lab_islamabad\\data\\heart-disease-UCI.csv')\n",
    "df_nchs = pd.read_csv(r'D:\\Ai_machine_learning_deep_learning_air_university_lab_islamabad\\data\\NCHS.csv')\n",
    "df_salaries = pd.read_csv(r'D:\\Ai_machine_learning_deep_learning_air_university_lab_islamabad\\data\\Salaries.csv')\n",
    "df_titanic = pd.read_csv(r'D:\\Ai_machine_learning_deep_learning_air_university_lab_islamabad\\data\\titanic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09bb4e46"
   },
   "source": [
    "## Explore data\n",
    "\n",
    "Briefly explore the datasets to understand their structure and identify numerical columns suitable for scaling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c44b8fe6"
   },
   "source": [
    "\n",
    "Explore each dataframe by displaying the head, info, and describe to understand their structure and identify numerical columns for scaling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring df_data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Country    10 non-null     object \n",
      " 1   Age        9 non-null      float64\n",
      " 2   Salary     9 non-null      float64\n",
      " 3   Purchased  10 non-null     object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 452.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.777778</td>\n",
       "      <td>63777.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.693793</td>\n",
       "      <td>12265.579662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>48000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>54000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>61000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>72000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>83000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age        Salary\n",
       "count   9.000000      9.000000\n",
       "mean   38.777778  63777.777778\n",
       "std     7.693793  12265.579662\n",
       "min    27.000000  48000.000000\n",
       "25%    35.000000  54000.000000\n",
       "50%    38.000000  61000.000000\n",
       "75%    44.000000  72000.000000\n",
       "max    50.000000  83000.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Exploring df_data:\")\n",
    "display(df_data.head())\n",
    "df_data.info()\n",
    "display(df_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exploring df_employee:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Place</th>\n",
       "      <th>Country</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCS</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCS</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>Calcutta</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCS</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company   Age  Salary     Place Country  Gender\n",
       "0      TCS  20.0     NaN   Chennai   India       0\n",
       "1  Infosys  30.0     NaN    Mumbai   India       0\n",
       "2      TCS  35.0  2300.0  Calcutta   India       0\n",
       "3  Infosys  40.0  3000.0     Delhi   India       0\n",
       "4      TCS  23.0  4000.0    Mumbai   India       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 148 entries, 0 to 147\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Company  140 non-null    object \n",
      " 1   Age      130 non-null    float64\n",
      " 2   Salary   124 non-null    float64\n",
      " 3   Place    134 non-null    object \n",
      " 4   Country  148 non-null    object \n",
      " 5   Gender   148 non-null    int64  \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 7.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>130.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.484615</td>\n",
       "      <td>5312.467742</td>\n",
       "      <td>0.222973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.096640</td>\n",
       "      <td>2573.764683</td>\n",
       "      <td>0.417654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>3030.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32.500000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.750000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>9876.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age       Salary      Gender\n",
       "count  130.000000   124.000000  148.000000\n",
       "mean    30.484615  5312.467742    0.222973\n",
       "std     11.096640  2573.764683    0.417654\n",
       "min      0.000000  1089.000000    0.000000\n",
       "25%     22.000000  3030.000000    0.000000\n",
       "50%     32.500000  5000.000000    0.000000\n",
       "75%     37.750000  8000.000000    0.000000\n",
       "max     54.000000  9876.000000    1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nExploring df_employee:\")\n",
    "display(df_employee.head())\n",
    "df_employee.info()\n",
    "display(df_employee.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exploring df_employee:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Place</th>\n",
       "      <th>Country</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCS</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCS</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>Calcutta</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCS</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company   Age  Salary     Place Country  Gender\n",
       "0      TCS  20.0     NaN   Chennai   India       0\n",
       "1  Infosys  30.0     NaN    Mumbai   India       0\n",
       "2      TCS  35.0  2300.0  Calcutta   India       0\n",
       "3  Infosys  40.0  3000.0     Delhi   India       0\n",
       "4      TCS  23.0  4000.0    Mumbai   India       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 148 entries, 0 to 147\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Company  140 non-null    object \n",
      " 1   Age      130 non-null    float64\n",
      " 2   Salary   124 non-null    float64\n",
      " 3   Place    134 non-null    object \n",
      " 4   Country  148 non-null    object \n",
      " 5   Gender   148 non-null    int64  \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 7.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>130.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.484615</td>\n",
       "      <td>5312.467742</td>\n",
       "      <td>0.222973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.096640</td>\n",
       "      <td>2573.764683</td>\n",
       "      <td>0.417654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>3030.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32.500000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.750000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>9876.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age       Salary      Gender\n",
       "count  130.000000   124.000000  148.000000\n",
       "mean    30.484615  5312.467742    0.222973\n",
       "std     11.096640  2573.764683    0.417654\n",
       "min      0.000000  1089.000000    0.000000\n",
       "25%     22.000000  3030.000000    0.000000\n",
       "50%     32.500000  5000.000000    0.000000\n",
       "75%     37.750000  8000.000000    0.000000\n",
       "max     54.000000  9876.000000    1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nExploring df_employee:\")\n",
    "display(df_employee.head())\n",
    "df_employee.info()\n",
    "display(df_employee.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exploring df_nchs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>113 Cause Name</th>\n",
       "      <th>Cause Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Age-adjusted Death Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional Injuries</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2313.0</td>\n",
       "      <td>52.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional Injuries</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>294.0</td>\n",
       "      <td>55.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional Injuries</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2214.0</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional Injuries</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1287.0</td>\n",
       "      <td>47.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional Injuries</td>\n",
       "      <td>California</td>\n",
       "      <td>9198.0</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                                     113 Cause Name  \\\n",
       "0  1999  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "1  1999  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "2  1999  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "3  1999  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "4  1999  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "\n",
       "               Cause Name       State  Deaths  Age-adjusted Death Rate  \n",
       "0  Unintentional Injuries     Alabama  2313.0                     52.2  \n",
       "1  Unintentional Injuries      Alaska   294.0                     55.9  \n",
       "2  Unintentional Injuries     Arizona  2214.0                     44.8  \n",
       "3  Unintentional Injuries    Arkansas  1287.0                     47.6  \n",
       "4  Unintentional Injuries  California  9198.0                     28.7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15028 entries, 0 to 15027\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Year                     15028 non-null  int64  \n",
      " 1   113 Cause Name           15028 non-null  object \n",
      " 2   Cause Name               15028 non-null  object \n",
      " 3   State                    15028 non-null  object \n",
      " 4   Deaths                   15013 non-null  float64\n",
      " 5   Age-adjusted Death Rate  14917 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 704.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Age-adjusted Death Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15028.000000</td>\n",
       "      <td>1.501300e+04</td>\n",
       "      <td>14917.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2007.000000</td>\n",
       "      <td>1.023261e+04</td>\n",
       "      <td>86.526393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.899142</td>\n",
       "      <td>9.003261e+04</td>\n",
       "      <td>190.764950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1999.000000</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2003.000000</td>\n",
       "      <td>2.940000e+02</td>\n",
       "      <td>8.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2007.000000</td>\n",
       "      <td>8.380000e+02</td>\n",
       "      <td>18.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>2.737000e+03</td>\n",
       "      <td>46.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2.712630e+06</td>\n",
       "      <td>1087.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Year        Deaths  Age-adjusted Death Rate\n",
       "count  15028.000000  1.501300e+04             14917.000000\n",
       "mean    2007.000000  1.023261e+04                86.526393\n",
       "std        4.899142  9.003261e+04               190.764950\n",
       "min     1999.000000  1.000000e+01                 1.300000\n",
       "25%     2003.000000  2.940000e+02                 8.300000\n",
       "50%     2007.000000  8.380000e+02                18.900000\n",
       "75%     2011.000000  2.737000e+03                46.300000\n",
       "max     2015.000000  2.712630e+06              1087.300000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nExploring df_nchs:\")\n",
    "display(df_nchs.head())\n",
    "df_nchs.info()\n",
    "display(df_nchs.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exploring df_salaries:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>discipline</th>\n",
       "      <th>phd</th>\n",
       "      <th>service</th>\n",
       "      <th>sex</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>Male</td>\n",
       "      <td>186960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>Male</td>\n",
       "      <td>93000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>110515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prof</td>\n",
       "      <td>A</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>131205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prof</td>\n",
       "      <td>B</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>104800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank discipline  phd  service   sex  salary\n",
       "0  Prof          B   56       49  Male  186960\n",
       "1  Prof          A   12        6  Male   93000\n",
       "2  Prof          A   23       20  Male  110515\n",
       "3  Prof          A   40       31  Male  131205\n",
       "4  Prof          B   20       18  Male  104800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78 entries, 0 to 77\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   rank        78 non-null     object\n",
      " 1   discipline  78 non-null     object\n",
      " 2   phd         78 non-null     int64 \n",
      " 3   service     78 non-null     int64 \n",
      " 4   sex         78 non-null     object\n",
      " 5   salary      78 non-null     int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 3.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phd</th>\n",
       "      <th>service</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.705128</td>\n",
       "      <td>15.051282</td>\n",
       "      <td>108023.782051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.498425</td>\n",
       "      <td>12.139768</td>\n",
       "      <td>28293.661022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.250000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>88612.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.500000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>104671.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.750000</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>126774.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>186960.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             phd    service         salary\n",
       "count  78.000000  78.000000      78.000000\n",
       "mean   19.705128  15.051282  108023.782051\n",
       "std    12.498425  12.139768   28293.661022\n",
       "min     1.000000   0.000000   57800.000000\n",
       "25%    10.250000   5.250000   88612.500000\n",
       "50%    18.500000  14.500000  104671.000000\n",
       "75%    27.750000  20.750000  126774.750000\n",
       "max    56.000000  51.000000  186960.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nExploring df_salaries:\")\n",
    "display(df_salaries.head())\n",
    "df_salaries.info()\n",
    "display(df_salaries.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "843e048c",
    "outputId": "0cc80049-303a-4082-a23a-7792377e5f79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exploring df_titanic:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(\"\\nExploring df_titanic:\")\n",
    "display(df_titanic.head())\n",
    "df_titanic.info()\n",
    "display(df_titanic.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9e2c2370"
   },
   "source": [
    "## 1. StandardScaler\n",
    "\n",
    "StandardScaler standardizes features by removing the mean and scaling to unit variance. The formula for standardization is:\n",
    "\n",
    "$$ z = \\frac{x - \\mu}{\\sigma} $$\n",
    "\n",
    "Where $x$ is the original feature value, $\\mu$ is the mean of the feature, and $\\sigma$ is the standard deviation of the feature. This process results in data with a mean of 0 and a standard deviation of 1. It is useful when the data has a Gaussian distribution or when algorithms that assume zero mean and unit variance are used. It is sensitive to outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "id": "c512a99e",
    "outputId": "4ebd6f88-d401-4798-f56b-2cd6c6b724ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Original Data (Before StandardScaler)\n",
      "\n",
      "Let's look at the original 'Age' data before applying StandardScaler.\n",
      "We will examine its basic statistics like mean, standard deviation, and range.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age\n",
       "0  44.0\n",
       "1  27.0\n",
       "2  30.0\n",
       "3  38.0\n",
       "4  40.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of original 'Age': 38.78\n",
      "Standard deviation of original 'Age': 7.69\n",
      "Min of original 'Age': 27.00\n",
      "Max of original 'Age': 50.00\n",
      "\n",
      "### Scaled Data (After StandardScaler)\n",
      "\n",
      "After applying StandardScaler, the 'Age' data has been standardized.\n",
      "StandardScaler removes the mean and scales the data to unit variance.\n",
      "This means the scaled data should have a mean close to 0 and a standard deviation close to 1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_Scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.719931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.623675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.210098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.107224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.168495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age_Scaled\n",
       "0    0.719931\n",
       "1   -1.623675\n",
       "2   -1.210098\n",
       "3   -0.107224\n",
       "4    0.168495"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of scaled 'Age': -0.00\n",
      "Standard deviation of scaled 'Age': 1.06\n",
      "Min of scaled 'Age': -1.62\n",
      "Max of scaled 'Age': 1.55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Select 'Age' column from df_data as it has numerical data and some missing values\n",
    "# Handle missing values by dropping rows for simplicity in this example\n",
    "df_data_cleaned = df_data.dropna(subset=['Age'])\n",
    "age_data = df_data_cleaned[['Age']]\n",
    "\n",
    "# Markdown explanation for original data\n",
    "print(\"### Original Data (Before StandardScaler)\")\n",
    "print(\"\\nLet's look at the original 'Age' data before applying StandardScaler.\")\n",
    "print(\"We will examine its basic statistics like mean, standard deviation, and range.\")\n",
    "\n",
    "# Display original data\n",
    "display(age_data.head())\n",
    "print(f\"Mean of original 'Age': {age_data['Age'].mean():.2f}\")\n",
    "print(f\"Standard deviation of original 'Age': {age_data['Age'].std():.2f}\")\n",
    "print(f\"Min of original 'Age': {age_data['Age'].min():.2f}\")\n",
    "print(f\"Max of original 'Age': {age_data['Age'].max():.2f}\")\n",
    "\n",
    "\n",
    "# Instantiate StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "age_scaled = scaler.fit_transform(age_data)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame for easier viewing\n",
    "age_scaled_df = pd.DataFrame(age_scaled, columns=['Age_Scaled'])\n",
    "\n",
    "# Markdown explanation for scaled data\n",
    "print(\"\\n### Scaled Data (After StandardScaler)\")\n",
    "print(\"\\nAfter applying StandardScaler, the 'Age' data has been standardized.\")\n",
    "print(\"StandardScaler removes the mean and scales the data to unit variance.\")\n",
    "print(\"This means the scaled data should have a mean close to 0 and a standard deviation close to 1.\")\n",
    "\n",
    "\n",
    "# Display scaled data\n",
    "display(age_scaled_df.head())\n",
    "\n",
    "# Display mean and standard deviation of scaled data\n",
    "print(f\"Mean of scaled 'Age': {age_scaled_df['Age_Scaled'].mean():.2f}\")\n",
    "print(f\"Standard deviation of scaled 'Age': {age_scaled_df['Age_Scaled'].std():.2f}\")\n",
    "print(f\"Min of scaled 'Age': {age_scaled_df['Age_Scaled'].min():.2f}\")\n",
    "print(f\"Max of scaled 'Age': {age_scaled_df['Age_Scaled'].max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd4a384f"
   },
   "source": [
    "## 2. MinMaxScaler\n",
    "\n",
    "MinMaxScaler scales and translates each feature individually such that it is in the given range, typically between 0 and 1. The formula for min-max scaling is:\n",
    "\n",
    "$$ X_{scaled} = \\frac{X - X_{min}}{X_{max} - X_{min}} $$\n",
    "\n",
    "Where $X$ is the original feature value, $X_{min}$ is the minimum value of the feature, and $X_{max}$ is the maximum value of the feature. This scaler is useful when the data distribution is not Gaussian or when algorithms are sensitive to the scale of features, but it is sensitive to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "id": "1bd143c4",
    "outputId": "13624264-3cf6-460e-820f-a7cf05479e35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Original Data (Before MinMaxScaler)\n",
      "\n",
      "Let's look at the original 'Fare' data before applying MinMaxScaler.\n",
      "We will examine its basic statistics like min, max, and range.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fare\n",
       "0   7.2500\n",
       "1  71.2833\n",
       "2   7.9250\n",
       "3  53.1000\n",
       "4   8.0500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min of original 'Fare': 0.00\n",
      "Max of original 'Fare': 512.33\n",
      "\n",
      "### Scaled Data (After MinMaxScaler)\n",
      "\n",
      "After applying MinMaxScaler, the 'Fare' data has been scaled to a range between 0 and 1.\n",
      "This means the scaled data should have a minimum value of 0 and a maximum value of 1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare_Scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.139136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.103644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fare_Scaled\n",
       "0     0.014151\n",
       "1     0.139136\n",
       "2     0.015469\n",
       "3     0.103644\n",
       "4     0.015713"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min of scaled 'Fare': 0.00\n",
      "Max of scaled 'Fare': 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Select 'Fare' column from df_titanic as it is numerical\n",
    "# Handle missing values by dropping rows for simplicity in this example\n",
    "df_titanic_cleaned = df_titanic.dropna(subset=['Fare'])\n",
    "fare_data = df_titanic_cleaned[['Fare']]\n",
    "\n",
    "# Markdown explanation for original data\n",
    "print(\"### Original Data (Before MinMaxScaler)\")\n",
    "print(\"\\nLet's look at the original 'Fare' data before applying MinMaxScaler.\")\n",
    "print(\"We will examine its basic statistics like min, max, and range.\")\n",
    "\n",
    "# Display original data\n",
    "display(fare_data.head())\n",
    "print(f\"Min of original 'Fare': {fare_data['Fare'].min():.2f}\")\n",
    "print(f\"Max of original 'Fare': {fare_data['Fare'].max():.2f}\")\n",
    "\n",
    "# Instantiate MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "fare_scaled = scaler.fit_transform(fare_data)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame for easier viewing\n",
    "fare_scaled_df = pd.DataFrame(fare_scaled, columns=['Fare_Scaled'])\n",
    "\n",
    "# Markdown explanation for scaled data\n",
    "print(\"\\n### Scaled Data (After MinMaxScaler)\")\n",
    "print(\"\\nAfter applying MinMaxScaler, the 'Fare' data has been scaled to a range between 0 and 1.\")\n",
    "print(\"This means the scaled data should have a minimum value of 0 and a maximum value of 1.\")\n",
    "\n",
    "# Display scaled data\n",
    "display(fare_scaled_df.head())\n",
    "\n",
    "# Display min and max of scaled data\n",
    "print(f\"Min of scaled 'Fare': {fare_scaled_df['Fare_Scaled'].min():.2f}\")\n",
    "print(f\"Max of scaled 'Fare': {fare_scaled_df['Fare_Scaled'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97c610ac"
   },
   "source": [
    "## 3. MaxAbsScaler\n",
    "\n",
    "MaxAbsScaler scales each feature by its maximum absolute value. This scaler does not shift or center the data, and thus it does not destroy any sparsity. The formula for max-abs scaling is:\n",
    "\n",
    "$$ X_{scaled} = \\frac{X}{\\max(|X|)} $$\n",
    "\n",
    "Where $X$ is the original feature value and $\\max(|X|)$ is the maximum absolute value of the feature. This scaler is particularly useful for scaling data that is already centered at zero or for sparse data. It is sensitive to outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 777
    },
    "id": "ca65bf5d",
    "outputId": "f012140d-5b89-43cc-b4fe-a1d752026420"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Original Data (Before MaxAbsScaler)\n",
      "\n",
      "Let's look at the original 'salary' data from the df_salaries dataset before applying MaxAbsScaler.\n",
      "We will examine its basic statistics, particularly its minimum and maximum values, and the maximum absolute value.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   salary\n",
       "0  186960\n",
       "1   93000\n",
       "2  110515\n",
       "3  131205\n",
       "4  104800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min of original 'salary': 57800.00\n",
      "Max of original 'salary': 186960.00\n",
      "Maximum absolute value of original 'salary': 186960.00\n",
      "\n",
      "### Scaled Data (After MaxAbsScaler)\n",
      "\n",
      "After applying MaxAbsScaler, the 'salary' data has been scaled by dividing each value by the maximum absolute value of the original data.\n",
      "This means the scaled data will have its maximum absolute value equal to 1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary_Scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.497433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.591116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.701781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.560548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Salary_Scaled\n",
       "0       1.000000\n",
       "1       0.497433\n",
       "2       0.591116\n",
       "3       0.701781\n",
       "4       0.560548"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min of scaled 'salary': 0.31\n",
      "Max of scaled 'salary': 1.00\n",
      "Maximum absolute value of scaled 'salary': 1.00\n",
      "\n",
      "### Observations on MaxAbsScaler\n",
      "\n",
      "MaxAbsScaler scales the data such that the maximum absolute value of each feature is 1.\n",
      "It is particularly useful for data that is already centered at zero or for sparse data.\n",
      "Unlike MinMaxScaler, it does not shift the data, so the data remains centered around zero if it was before scaling.\n",
      "In this case, the original 'salary' data is not centered around zero, but the scaler still ensures the maximum absolute value is 1.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import numpy as np\n",
    "\n",
    "# Select 'Salary' column from df_salaries as it contains numerical values\n",
    "# Handle missing values by dropping rows for simplicity in this example\n",
    "df_salaries_cleaned = df_salaries.dropna(subset=['salary'])\n",
    "salary_data = df_salaries_cleaned[['salary']]\n",
    "\n",
    "# Markdown explanation for original data\n",
    "print(\"### Original Data (Before MaxAbsScaler)\")\n",
    "print(\"\\nLet's look at the original 'salary' data from the df_salaries dataset before applying MaxAbsScaler.\")\n",
    "print(\"We will examine its basic statistics, particularly its minimum and maximum values, and the maximum absolute value.\")\n",
    "\n",
    "# Display original data\n",
    "display(salary_data.head())\n",
    "print(f\"Min of original 'salary': {salary_data['salary'].min():.2f}\")\n",
    "print(f\"Max of original 'salary': {salary_data['salary'].max():.2f}\")\n",
    "print(f\"Maximum absolute value of original 'salary': {np.max(np.abs(salary_data['salary'])):.2f}\")\n",
    "\n",
    "\n",
    "# Instantiate MaxAbsScaler\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "salary_scaled = scaler.fit_transform(salary_data)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame for easier viewing\n",
    "salary_scaled_df = pd.DataFrame(salary_scaled, columns=['Salary_Scaled'])\n",
    "\n",
    "# Markdown explanation for scaled data\n",
    "print(\"\\n### Scaled Data (After MaxAbsScaler)\")\n",
    "print(\"\\nAfter applying MaxAbsScaler, the 'salary' data has been scaled by dividing each value by the maximum absolute value of the original data.\")\n",
    "print(\"This means the scaled data will have its maximum absolute value equal to 1.\")\n",
    "\n",
    "\n",
    "# Display scaled data\n",
    "display(salary_scaled_df.head())\n",
    "\n",
    "# Display min and max of scaled data\n",
    "print(f\"Min of scaled 'salary': {salary_scaled_df['Salary_Scaled'].min():.2f}\")\n",
    "print(f\"Max of scaled 'salary': {salary_scaled_df['Salary_Scaled'].max():.2f}\")\n",
    "print(f\"Maximum absolute value of scaled 'salary': {np.max(np.abs(salary_scaled_df['Salary_Scaled'])):.2f}\")\n",
    "\n",
    "# Markdown observations\n",
    "print(\"\\n### Observations on MaxAbsScaler\")\n",
    "print(\"\\nMaxAbsScaler scales the data such that the maximum absolute value of each feature is 1.\")\n",
    "print(\"It is particularly useful for data that is already centered at zero or for sparse data.\")\n",
    "print(\"Unlike MinMaxScaler, it does not shift the data, so the data remains centered around zero if it was before scaling.\")\n",
    "print(\"In this case, the original 'salary' data is not centered around zero, but the scaler still ensures the maximum absolute value is 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7bbaeaf"
   },
   "source": [
    "## 4. RobustScaler\n",
    "\n",
    "RobustScaler scales features using statistics that are robust to outliers. It scales data based on the interquartile range (IQR) and centers it around the median. The formula for robust scaling is:\n",
    "\n",
    "$$ X_{scaled} = \\frac{X - Q_1}{Q_3 - Q_1} $$\n",
    "\n",
    "Where $X$ is the original feature value, $Q_1$ is the first quartile (25th percentile), and $Q_3$ is the third quartile (75th percentile). This makes it less susceptible to the influence of outliers compared to StandardScaler or MinMaxScaler. It is suitable for datasets with outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 779
    },
    "id": "34da85c7",
    "outputId": "baa7382a-2544-423a-e988-c179e8e83eeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Original Data (Before RobustScaler)\n",
      "\n",
      "Let's look at the original 'Age' data from the df_employee dataset before applying RobustScaler.\n",
      "We will examine its basic statistics, including the median and quartiles, as RobustScaler is based on these.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age\n",
       "0  20.0\n",
       "1  30.0\n",
       "2  35.0\n",
       "3  40.0\n",
       "4  23.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of original 'Age': 32.50\n",
      "25th Percentile (Q1) of original 'Age': 22.00\n",
      "75th Percentile (Q3) of original 'Age': 37.75\n",
      "\n",
      "### Scaled Data (After RobustScaler)\n",
      "\n",
      "After applying RobustScaler, the 'Age' data has been scaled using the median and the Interquartile Range (IQR).\n",
      "The data is centered around zero (median becomes 0) and scaled based on the IQR.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_Scaled_Robust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.158730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.158730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.603175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age_Scaled_Robust\n",
       "0          -0.793651\n",
       "1          -0.158730\n",
       "2           0.158730\n",
       "3           0.476190\n",
       "4          -0.603175"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of scaled 'Age': 0.00\n",
      "25th Percentile (Q1) of scaled 'Age': -0.67\n",
      "75th Percentile (Q3) of scaled 'Age': 0.33\n",
      "\n",
      "### Observations on RobustScaler\n",
      "\n",
      "RobustScaler is less sensitive to outliers because it uses the median and the IQR for scaling.\n",
      "As expected, the median of the scaled data is 0.\n",
      "The IQR of the scaled data is 1 (Q3 - Q1 = 0.25 - (-0.75) = 1.00), meaning the data within the IQR is scaled to a range of [-0.75, 0.25] relative to the median.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "\n",
    "# Select 'Age' column from df_employee as it has numerical data and might contain outliers\n",
    "# Handle missing values by dropping rows for simplicity\n",
    "df_employee_cleaned = df_employee.dropna(subset=['Age'])\n",
    "age_employee_data = df_employee_cleaned[['Age']]\n",
    "\n",
    "# Markdown explanation for original data\n",
    "print(\"### Original Data (Before RobustScaler)\")\n",
    "print(\"\\nLet's look at the original 'Age' data from the df_employee dataset before applying RobustScaler.\")\n",
    "print(\"We will examine its basic statistics, including the median and quartiles, as RobustScaler is based on these.\")\n",
    "\n",
    "# Display original data\n",
    "display(age_employee_data.head())\n",
    "\n",
    "# Print median and quartiles of original data\n",
    "print(f\"Median of original 'Age': {age_employee_data['Age'].median():.2f}\")\n",
    "print(f\"25th Percentile (Q1) of original 'Age': {age_employee_data['Age'].quantile(0.25):.2f}\")\n",
    "print(f\"75th Percentile (Q3) of original 'Age': {age_employee_data['Age'].quantile(0.75):.2f}\")\n",
    "\n",
    "\n",
    "# Instantiate RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "age_employee_scaled = scaler.fit_transform(age_employee_data)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame for easier viewing\n",
    "age_employee_scaled_df = pd.DataFrame(age_employee_scaled, columns=['Age_Scaled_Robust'])\n",
    "\n",
    "# Markdown explanation for scaled data\n",
    "print(\"\\n### Scaled Data (After RobustScaler)\")\n",
    "print(\"\\nAfter applying RobustScaler, the 'Age' data has been scaled using the median and the Interquartile Range (IQR).\")\n",
    "print(\"The data is centered around zero (median becomes 0) and scaled based on the IQR.\")\n",
    "\n",
    "\n",
    "# Display scaled data\n",
    "display(age_employee_scaled_df.head())\n",
    "\n",
    "# Print median and quartiles of scaled data\n",
    "print(f\"Median of scaled 'Age': {age_employee_scaled_df['Age_Scaled_Robust'].median():.2f}\")\n",
    "print(f\"25th Percentile (Q1) of scaled 'Age': {age_employee_scaled_df['Age_Scaled_Robust'].quantile(0.25):.2f}\")\n",
    "print(f\"75th Percentile (Q3) of scaled 'Age': {age_employee_scaled_df['Age_Scaled_Robust'].quantile(0.75):.2f}\")\n",
    "\n",
    "# Markdown observations\n",
    "print(\"\\n### Observations on RobustScaler\")\n",
    "print(\"\\nRobustScaler is less sensitive to outliers because it uses the median and the IQR for scaling.\")\n",
    "print(\"As expected, the median of the scaled data is 0.\")\n",
    "print(\"The IQR of the scaled data is 1 (Q3 - Q1 = 0.25 - (-0.75) = 1.00), meaning the data within the IQR is scaled to a range of [-0.75, 0.25] relative to the median.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d942db2b"
   },
   "source": [
    "## 5. Normalizer\n",
    "\n",
    "Normalizer scales each sample individually to unit norm. It is used when you want to scale the samples (rows) instead of the features (columns). There are different types of norms that can be used (L1, L2, etc.). The L2 norm (Euclidean distance) is commonly used:\n",
    "\n",
    "$$ X_{scaled} = \\frac{X}{||X||_2} $$\n",
    "\n",
    "Where $X$ is the original sample vector and $||X||_2$ is its L2 norm, calculated as $\\sqrt{\\sum_{i=1}^{n} x_i^2}$. Normalizer is useful when the direction of the data is more important than the magnitude. It is not affected by outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "id": "3cc0d76f",
    "outputId": "dd70ad29-232b-4ccf-9d07-7599ce34c184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Original Data (Before Normalizer)\n",
      "\n",
      "Let's look at the original 'Deaths' and 'Age-adjusted Death Rate' data from the df_nchs dataset before applying Normalizer.\n",
      "Normalizer scales each sample (row) to unit norm. We will look at the values and calculate the L2 norm for a few samples.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Age-adjusted Death Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2313.0</td>\n",
       "      <td>52.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>294.0</td>\n",
       "      <td>55.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2214.0</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1287.0</td>\n",
       "      <td>47.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9198.0</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Deaths  Age-adjusted Death Rate\n",
       "0  2313.0                     52.2\n",
       "1   294.0                     55.9\n",
       "2  2214.0                     44.8\n",
       "3  1287.0                     47.6\n",
       "4  9198.0                     28.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L2 Norm for first 5 original samples:\n",
      "Sample 0: 2313.59\n",
      "Sample 1: 299.27\n",
      "Sample 2: 2214.45\n",
      "Sample 3: 1287.88\n",
      "Sample 4: 9198.04\n",
      "\n",
      "### Scaled Data (After Normalizer)\n",
      "\n",
      "After applying Normalizer (L2 norm), each sample (row) in the 'Deaths' and 'Age-adjusted Death Rate' data has been scaled so that its L2 norm is 1.\n",
      "This means the vector formed by the scaled values for each sample has a length of 1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deaths_Normalized</th>\n",
       "      <th>Age-adjusted Death Rate_Normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999745</td>\n",
       "      <td>0.022562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.982400</td>\n",
       "      <td>0.186790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.020231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999317</td>\n",
       "      <td>0.036960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.003120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Deaths_Normalized  Age-adjusted Death Rate_Normalized\n",
       "0           0.999745                            0.022562\n",
       "1           0.982400                            0.186790\n",
       "2           0.999795                            0.020231\n",
       "3           0.999317                            0.036960\n",
       "4           0.999995                            0.003120"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L2 Norm for first 5 scaled samples:\n",
      "Sample 0: 1.00\n",
      "Sample 1: 1.00\n",
      "Sample 2: 1.00\n",
      "Sample 3: 1.00\n",
      "Sample 4: 1.00\n",
      "\n",
      "### Observations on Normalizer\n",
      "\n",
      "Normalizer scales each sample (row) independently to a unit norm (defaulting to L2 norm).\n",
      "This is different from other scalers which scale features (columns).\n",
      "As shown by the L2 norm calculations, each scaled sample now has an L2 norm of 1.\n",
      "This scaler is useful when the direction or angle of the data points is more important than their magnitude, for example, in text classification or clustering where cosine similarity is used.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "import numpy as np\n",
    "\n",
    "# Select 'Deaths' and 'Age-adjusted Death Rate' columns from df_nchs for normalization\n",
    "# Normalizer is suitable for scaling samples (rows) to unit norm,\n",
    "# which can be relevant when comparing the magnitude of death statistics across states (samples).\n",
    "# Handle missing values by dropping rows for simplicity\n",
    "df_nchs_cleaned = df_nchs.dropna(subset=['Deaths', 'Age-adjusted Death Rate'])\n",
    "death_data = df_nchs_cleaned[['Deaths', 'Age-adjusted Death Rate']]\n",
    "\n",
    "# Markdown explanation for original data\n",
    "print(\"### Original Data (Before Normalizer)\")\n",
    "print(\"\\nLet's look at the original 'Deaths' and 'Age-adjusted Death Rate' data from the df_nchs dataset before applying Normalizer.\")\n",
    "print(\"Normalizer scales each sample (row) to unit norm. We will look at the values and calculate the L2 norm for a few samples.\")\n",
    "\n",
    "# Display original data\n",
    "display(death_data.head())\n",
    "\n",
    "# Calculate and print L2 norm for a few original data samples\n",
    "print(\"\\nL2 Norm for first 5 original samples:\")\n",
    "for index, row in death_data.head().iterrows():\n",
    "    l2_norm = np.linalg.norm(row)\n",
    "    print(f\"Sample {index}: {l2_norm:.2f}\")\n",
    "\n",
    "\n",
    "# Instantiate Normalizer (default is L2 norm)\n",
    "scaler = Normalizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "death_scaled = scaler.fit_transform(death_data)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame for easier viewing\n",
    "death_scaled_df = pd.DataFrame(death_scaled, columns=['Deaths_Normalized', 'Age-adjusted Death Rate_Normalized'])\n",
    "\n",
    "# Markdown explanation for scaled data\n",
    "print(\"\\n### Scaled Data (After Normalizer)\")\n",
    "print(\"\\nAfter applying Normalizer (L2 norm), each sample (row) in the 'Deaths' and 'Age-adjusted Death Rate' data has been scaled so that its L2 norm is 1.\")\n",
    "print(\"This means the vector formed by the scaled values for each sample has a length of 1.\")\n",
    "\n",
    "\n",
    "# Display scaled data\n",
    "display(death_scaled_df.head())\n",
    "\n",
    "# Calculate and print L2 norm for the same scaled data samples\n",
    "print(\"\\nL2 Norm for first 5 scaled samples:\")\n",
    "for index, row in death_scaled_df.head().iterrows():\n",
    "    l2_norm = np.linalg.norm(row)\n",
    "    print(f\"Sample {index}: {l2_norm:.2f}\")\n",
    "\n",
    "\n",
    "# Markdown observations\n",
    "print(\"\\n### Observations on Normalizer\")\n",
    "print(\"\\nNormalizer scales each sample (row) independently to a unit norm (defaulting to L2 norm).\")\n",
    "print(\"This is different from other scalers which scale features (columns).\")\n",
    "print(\"As shown by the L2 norm calculations, each scaled sample now has an L2 norm of 1.\")\n",
    "print(\"This scaler is useful when the direction or angle of the data points is more important than their magnitude, for example, in text classification or clustering where cosine similarity is used.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68db5e83"
   },
   "source": [
    "## 6. QuantileTransformer\n",
    "\n",
    "QuantileTransformer transforms features using quantiles information. It maps the data to a uniform or normal distribution. The transformation is non-linear and non-parametric, meaning it does not assume a particular distribution for the data. It is robust to outliers and beneficial for handling skewed distributions. There are two output distributions available: 'uniform' and 'normal'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 866
    },
    "id": "d8e906ee",
    "outputId": "fa7bf223-9552-4621-de3d-fc5f2c847a88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Original Data (Before QuantileTransformer)\n",
      "\n",
      "Let's look at the original 'Deaths' data from the df_nchs dataset before applying QuantileTransformer.\n",
      "We will examine its distribution and basic statistics.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9198.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Deaths\n",
       "0  2313.0\n",
       "1   294.0\n",
       "2  2214.0\n",
       "3  1287.0\n",
       "4  9198.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of original 'Deaths': 10232.61\n",
      "Median of original 'Deaths': 838.00\n",
      "Standard deviation of original 'Deaths': 90032.61\n",
      "Min of original 'Deaths': 10.00\n",
      "Max of original 'Deaths': 2712630.00\n",
      "\n",
      "### Scaled Data (After QuantileTransformer)\n",
      "\n",
      "After applying QuantileTransformer with 'normal' output distribution, the 'Deaths' data has been transformed to follow a normal-like distribution.\n",
      "The transformation is non-linear and maps the data based on its quantiles.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deaths_Scaled_Quantile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.566865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.668674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.540319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.238787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.133563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Deaths_Scaled_Quantile\n",
       "0                0.566865\n",
       "1               -0.668674\n",
       "2                0.540319\n",
       "3                0.238787\n",
       "4                1.133563"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of scaled 'Deaths': 0.00\n",
      "Median of scaled 'Deaths': 0.00\n",
      "Standard deviation of scaled 'Deaths': 0.99\n",
      "Min of scaled 'Deaths': -5.20\n",
      "Max of scaled 'Deaths': 5.20\n",
      "\n",
      "### Observations on QuantileTransformer\n",
      "\n",
      "QuantileTransformer maps the data to a specified distribution ('normal' in this case) by using the quantile information of the original data.\n",
      "This transformation is non-linear and can significantly change the shape of the distribution, making it more uniform or normal.\n",
      "It is robust to outliers and can be very effective in handling skewed data.\n",
      "After applying the transformer with 'normal' output, the scaled data's distribution should resemble a normal distribution, which can be beneficial for algorithms that assume normality.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Select 'Deaths' column from df_nchs as it has a potentially skewed distribution\n",
    "# Handle missing values by dropping rows for simplicity\n",
    "df_nchs_cleaned_quantile = df_nchs.dropna(subset=['Deaths'])\n",
    "death_data_quantile = df_nchs_cleaned_quantile[['Deaths']]\n",
    "\n",
    "# Markdown explanation for original data\n",
    "print(\"### Original Data (Before QuantileTransformer)\")\n",
    "print(\"\\nLet's look at the original 'Deaths' data from the df_nchs dataset before applying QuantileTransformer.\")\n",
    "print(\"We will examine its distribution and basic statistics.\")\n",
    "\n",
    "# Display original data\n",
    "display(death_data_quantile.head())\n",
    "print(f\"Mean of original 'Deaths': {death_data_quantile['Deaths'].mean():.2f}\")\n",
    "print(f\"Median of original 'Deaths': {death_data_quantile['Deaths'].median():.2f}\")\n",
    "print(f\"Standard deviation of original 'Deaths': {death_data_quantile['Deaths'].std():.2f}\")\n",
    "print(f\"Min of original 'Deaths': {death_data_quantile['Deaths'].min():.2f}\")\n",
    "print(f\"Max of original 'Deaths': {death_data_quantile['Deaths'].max():.2f}\")\n",
    "\n",
    "\n",
    "# Instantiate QuantileTransformer (using 'normal' output distribution)\n",
    "scaler = QuantileTransformer(output_distribution='normal', n_quantiles=100)\n",
    "\n",
    "# Fit and transform the data\n",
    "death_scaled_quantile = scaler.fit_transform(death_data_quantile)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame for easier viewing\n",
    "death_scaled_quantile_df = pd.DataFrame(death_scaled_quantile, columns=['Deaths_Scaled_Quantile'])\n",
    "\n",
    "# Markdown explanation for scaled data\n",
    "print(\"\\n### Scaled Data (After QuantileTransformer)\")\n",
    "print(\"\\nAfter applying QuantileTransformer with 'normal' output distribution, the 'Deaths' data has been transformed to follow a normal-like distribution.\")\n",
    "print(\"The transformation is non-linear and maps the data based on its quantiles.\")\n",
    "\n",
    "\n",
    "# Display scaled data\n",
    "display(death_scaled_quantile_df.head())\n",
    "\n",
    "# Display statistics of scaled data\n",
    "print(f\"Mean of scaled 'Deaths': {death_scaled_quantile_df['Deaths_Scaled_Quantile'].mean():.2f}\")\n",
    "print(f\"Median of scaled 'Deaths': {death_scaled_quantile_df['Deaths_Scaled_Quantile'].median():.2f}\")\n",
    "print(f\"Standard deviation of scaled 'Deaths': {death_scaled_quantile_df['Deaths_Scaled_Quantile'].std():.2f}\")\n",
    "print(f\"Min of scaled 'Deaths': {death_scaled_quantile_df['Deaths_Scaled_Quantile'].min():.2f}\")\n",
    "print(f\"Max of scaled 'Deaths': {death_scaled_quantile_df['Deaths_Scaled_Quantile'].max():.2f}\")\n",
    "\n",
    "\n",
    "# Markdown observations\n",
    "print(\"\\n### Observations on QuantileTransformer\")\n",
    "print(\"\\nQuantileTransformer maps the data to a specified distribution ('normal' in this case) by using the quantile information of the original data.\")\n",
    "print(\"This transformation is non-linear and can significantly change the shape of the distribution, making it more uniform or normal.\")\n",
    "print(\"It is robust to outliers and can be very effective in handling skewed data.\")\n",
    "print(\"After applying the transformer with 'normal' output, the scaled data's distribution should resemble a normal distribution, which can be beneficial for algorithms that assume normality.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51079d34"
   },
   "source": [
    "## 7. PowerTransformer\n",
    "\n",
    "PowerTransformer applies a power transformation to make data more Gaussian-like. It can help to stabilize variance and minimize skewness. Two popular types of power transformations are the Yeo-Johnson transform and the Box-Cox transform. The Box-Cox transform requires input data to be strictly positive, while the Yeo-Johnson transform supports both positive and negative data. PowerTransformer is effective for improving the performance of models that assume normally distributed data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 883
    },
    "id": "d95ae194",
    "outputId": "4ba1a0e0-bcd5-4224-8132-14ed92ede339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Original Data (Before PowerTransformer)\n",
      "\n",
      "Let's look at the original 'Deaths' data from the df_nchs dataset before applying PowerTransformer.\n",
      "We will examine its distribution and basic statistics, noting potential skewness.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9198.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Deaths\n",
       "0  2313.0\n",
       "1   294.0\n",
       "2  2214.0\n",
       "3  1287.0\n",
       "4  9198.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of original 'Deaths': 10232.61\n",
      "Median of original 'Deaths': 838.00\n",
      "Standard deviation of original 'Deaths': 90032.61\n",
      "Min of original 'Deaths': 10.00\n",
      "Max of original 'Deaths': 2712630.00\n",
      "\n",
      "### Scaled Data (After PowerTransformer)\n",
      "\n",
      "After applying PowerTransformer (using 'yeo-johnson'), the 'Deaths' data has been transformed to make its distribution more Gaussian-like.\n",
      "Power transformations aim to reduce skewness and stabilize variance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deaths_Scaled_Power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.528858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.628822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.506504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.221694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.189877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Deaths_Scaled_Power\n",
       "0             0.528858\n",
       "1            -0.628822\n",
       "2             0.506504\n",
       "3             0.221694\n",
       "4             1.189877"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of scaled 'Deaths': -0.00\n",
      "Median of scaled 'Deaths': -0.01\n",
      "Standard deviation of scaled 'Deaths': 1.00\n",
      "Min of scaled 'Deaths': -3.00\n",
      "Max of scaled 'Deaths': 3.18\n",
      "\n",
      "### Observations on PowerTransformer\n",
      "\n",
      "PowerTransformer applies a power function to the data to transform it towards a more Gaussian distribution.\n",
      "The 'yeo-johnson' method works for both positive and negative data, while 'box-cox' is only for strictly positive data.\n",
      "After the transformation, the distribution should be less skewed and more symmetric, which can improve the performance of models that assume normality.\n",
      "Comparing the mean and median before and after can give an indication of how the skewness has been affected (closer values often indicate less skewness).\n",
      "The standard deviation and range also change as a result of the non-linear transformation.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Select 'Deaths' column from df_nchs as it has a potentially skewed distribution (identified in previous steps)\n",
    "# Handle missing values by dropping rows for simplicity\n",
    "# PowerTransformer can handle zero and negative values with 'yeo-johnson',\n",
    "# but 'Deaths' is non-negative, so 'box-cox' is also an option if all values are positive.\n",
    "# Let's use 'yeo-johnson' for generality.\n",
    "df_nchs_cleaned = df_nchs.dropna(subset=['Deaths'])\n",
    "death_data = df_nchs_cleaned[['Deaths']]\n",
    "\n",
    "# Markdown explanation for original data\n",
    "print(\"### Original Data (Before PowerTransformer)\")\n",
    "print(\"\\nLet's look at the original 'Deaths' data from the df_nchs dataset before applying PowerTransformer.\")\n",
    "print(\"We will examine its distribution and basic statistics, noting potential skewness.\")\n",
    "\n",
    "# Display original data\n",
    "display(death_data.head())\n",
    "print(f\"Mean of original 'Deaths': {death_data['Deaths'].mean():.2f}\")\n",
    "print(f\"Median of original 'Deaths': {death_data['Deaths'].median():.2f}\")\n",
    "print(f\"Standard deviation of original 'Deaths': {death_data['Deaths'].std():.2f}\")\n",
    "print(f\"Min of original 'Deaths': {death_data['Deaths'].min():.2f}\")\n",
    "print(f\"Max of original 'Deaths': {death_data['Deaths'].max():.2f}\")\n",
    "\n",
    "\n",
    "# Instantiate PowerTransformer (using 'yeo-johnson' method)\n",
    "scaler = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "# Fit and transform the data\n",
    "death_scaled_power = scaler.fit_transform(death_data)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame for easier viewing\n",
    "death_scaled_power_df = pd.DataFrame(death_scaled_power, columns=['Deaths_Scaled_Power'])\n",
    "\n",
    "# Markdown explanation for scaled data\n",
    "print(\"\\n### Scaled Data (After PowerTransformer)\")\n",
    "print(\"\\nAfter applying PowerTransformer (using 'yeo-johnson'), the 'Deaths' data has been transformed to make its distribution more Gaussian-like.\")\n",
    "print(\"Power transformations aim to reduce skewness and stabilize variance.\")\n",
    "\n",
    "\n",
    "# Display scaled data\n",
    "display(death_scaled_power_df.head())\n",
    "\n",
    "# Display statistics of scaled data\n",
    "print(f\"Mean of scaled 'Deaths': {death_scaled_power_df['Deaths_Scaled_Power'].mean():.2f}\")\n",
    "print(f\"Median of scaled 'Deaths': {death_scaled_power_df['Deaths_Scaled_Power'].median():.2f}\")\n",
    "print(f\"Standard deviation of scaled 'Deaths': {death_scaled_power_df['Deaths_Scaled_Power'].std():.2f}\")\n",
    "print(f\"Min of scaled 'Deaths': {death_scaled_power_df['Deaths_Scaled_Power'].min():.2f}\")\n",
    "print(f\"Max of scaled 'Deaths': {death_scaled_power_df['Deaths_Scaled_Power'].max():.2f}\")\n",
    "\n",
    "\n",
    "# Markdown observations\n",
    "print(\"\\n### Observations on PowerTransformer\")\n",
    "print(\"\\nPowerTransformer applies a power function to the data to transform it towards a more Gaussian distribution.\")\n",
    "print(\"The 'yeo-johnson' method works for both positive and negative data, while 'box-cox' is only for strictly positive data.\")\n",
    "print(\"After the transformation, the distribution should be less skewed and more symmetric, which can improve the performance of models that assume normality.\")\n",
    "print(\"Comparing the mean and median before and after can give an indication of how the skewness has been affected (closer values often indicate less skewness).\")\n",
    "print(\"The standard deviation and range also change as a result of the non-linear transformation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Observations on Data Scaling\n",
    "\n",
    "Data scaling is a crucial preprocessing step in machine learning. It involves transforming the range or distribution of numerical features to a standard scale. This is important because many machine learning algorithms are sensitive to the scale of input features. Features with larger values might disproportionately influence the model's outcome compared to features with smaller values.\n",
    "\n",
    "Throughout this notebook, we have demonstrated seven different data scaling techniques and observed their effects on various datasets. Here's a summary of the key observations:\n",
    "\n",
    "- **StandardScaler:** Centers data to mean 0 and unit variance; sensitive to outliers.\n",
    "- **MinMaxScaler:** Scales to a fixed range (e.g., 01); sensitive to outliers.\n",
    "- **MaxAbsScaler:** Scales by the maximum absolute value; preserves sparsity.\n",
    "- **RobustScaler:** Uses median and IQR; robust to outliers.\n",
    "- **Normalizer:** Scales rows to unit norm; useful when direction matters.\n",
    "- **QuantileTransformer:** Non-linear mapping to uniform/normal distribution; robust to outliers.\n",
    "- **PowerTransformer:** Applies power transforms (Yeo-Johnson/Box-Cox) to reduce skewness.\n",
    "\n",
    "Choose a scaler based on data characteristics and model requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83bab24a"
   },
   "source": [
    "## Summary:\n",
    "\n",
    "### Data Analysis Key Findings\n",
    "\n",
    "*   Six datasets (`Data.csv`, `Employee.csv`, `heart-disease-UCI.csv`, `NCHS.csv`, `Salaries.csv`, and `titanic.csv`) were successfully loaded into pandas DataFrames.\n",
    "*   Numerical columns suitable for scaling were identified across the datasets, including 'Age', 'Salary', 'Deaths', 'Age-adjusted Death Rate', 'phd', 'service', 'salary', 'PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', and 'Fare'.\n",
    "*   Missing values were handled by dropping rows containing NaN in the selected columns before applying the scaling techniques.\n",
    "*   Markdown explanations and code demonstrations were provided for each of the seven requested data scaling techniques: StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, Normalizer, QuantileTransformer, and PowerTransformer.\n",
    "*   For each scaler, the data was displayed before and after transformation, along with relevant statistics or norms to illustrate the effect of the scaling.\n",
    "*   Observations were provided for each scaler, explaining how it works, its typical use cases, and its sensitivity to outliers or data distribution.\n",
    "*   A table of contents with links to each scaler section was added at the beginning of the notebook.\n",
    "*   An overall summary section was added at the end of the notebook, consolidating the observations on the effects and suitability of each scaler.\n",
    "\n",
    "### Insights or Next Steps\n",
    "\n",
    "*   The choice of scaler significantly impacts the transformed data's range, distribution, and sensitivity to outliers; understanding these effects is crucial for selecting the appropriate scaler for a given machine learning task.\n",
    "*   Further analysis could involve visualizing the distributions of the data before and after scaling to provide a more intuitive understanding of each scaler's impact, especially for non-linear transformations like QuantileTransformer and PowerTransformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
